{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Import the packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\nfrom string import punctuation\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"shops df"},{"metadata":{"trusted":true},"cell_type":"code","source":"shops = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/shops.csv\")\nshops.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"item_category"},{"metadata":{"trusted":true},"cell_type":"code","source":"items_category = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv\")\nitems_category.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"items df"},{"metadata":{"trusted":true},"cell_type":"code","source":"items = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/items.csv\")\nitems.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see the top 10 and bottom 10 item categories\nitems_gb = items.groupby(\"item_category_id\").size().to_frame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items[items[\"item_category_id\"] == 60]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"sales df"},{"metadata":{"trusted":true},"cell_type":"code","source":"sales = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv\")\nsales.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's correct the shops df and also generate a few more features\ndef fix_shops(shops):\n    '''\n    This function modifies the shops df inplace.\n    It correct's 3 shops that we have found to be 'duplicates'\n    and also creates a few more features: extracts the city and encodes it using LabelEncoder\n    '''\n    \n    d = {0:57, 1:58, 10:11, 23:24}\n    \n    # this 'tricks' allows you to map a series to a dictionary, but all values that are not in the dictionary won't be affected\n    # it's handy since if we blindly map the values, the missings values will be replaced with nan\n    shops[\"shop_id\"] = shops[\"shop_id\"].apply(lambda x: d[x] if x in d.keys() else x)\n    \n    # replace all the punctuation in the shop_name columns\n    shops[\"shop_name_cleaned\"] = shops[\"shop_name\"].apply(lambda s: \"\".join([x for x in s if x not in punctuation]))\n    \n    # extract the city name\n    shops[\"city\"] = shops[\"shop_name_cleaned\"].apply(lambda s: s.split()[0])\n    # encode it using a simple LabelEncoder\n    shops[\"city_id\"] = LabelEncoder().fit_transform(shops['city'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# a simple function that creates a global df with all joins and also shops corrections\ndef create_df():\n    '''\n    This is a helper function that creates the train df.\n    '''\n    # import all df\n    shops = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/shops.csv\")\n    fix_shops(shops) # fix the shops as we have seen before\n    \n    items_category = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv\")\n    items = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/items.csv\")\n    sales = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv\")\n        # fix shop_id in sales so that we can later merge the df\n    d = {0:57, 1:58, 10:11, 23:24}\n    sales[\"shop_id\"] = sales[\"shop_id\"].apply(lambda x: d[x] if x in d.keys() else x)\n    \n    # create df by merging the previous dataframes\n    df = pd.merge(items, items_category, left_on = \"item_category_id\", right_on = \"item_category_id\")\n    df = pd.merge(sales, df, left_on = \"item_id\", right_on = \"item_id\")\n    df = pd.merge(df, shops, left_on = \"shop_id\", right_on = \"shop_id\")\n    \n    # convert to datetime and sort the values\n#     df[\"date\"] = pd.to_datetime(df[\"date\"], format = \"%d.%m.%Y\")\n    df.sort_values(by = [\"shop_id\", \"date\"], ascending = True, inplace = True)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = create_df()\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate the monthly sales\ndf[\"date\"] = pd.to_datetime(df[\"date\"], format = \"%d.%m.%Y\")\n\ndf[\"Year\"] = df[\"date\"].dt.year\ndf[\"Month\"] = df[\"date\"].dt.month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px # library for interactive plots\n\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# resample the data on a monthly basis\nx = df[[\"date\", \"item_cnt_day\"]].set_index(\"date\").resample(\"M\").sum()\n\nfig = px.line(x, x=x.index, y=x[\"item_cnt_day\"], title=\"Monthly sales\",labels={\n                     \"item_cnt_day\": \"\"\n                 },)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# perform the same operations but on a weekly basis\nx = df[[\"date\", \"item_cnt_day\"]].set_index(\"date\").resample(\"W\").sum()\n\nfig = px.line(x, x=x.index, y=x[\"item_cnt_day\"], title=\"Weekly sales\", labels={\n                     \"item_cnt_day\": \"\"})\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Represent the monthly sales (left plot) and weekly sales (right plot) for each shop"},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\n# Mark the national holidays in Russia and see if there is any connection with sales spikes.\nrussian_holidays_start = [\ndatetime.datetime(2013, 1, 1),\ndatetime.datetime(2013, 2, 23),\ndatetime.datetime(2013, 3, 8),\ndatetime.datetime(2013, 5, 1),\ndatetime.datetime(2013, 5, 9),\ndatetime.datetime(2013, 6, 12),\ndatetime.datetime(2013, 11, 4),\n\ndatetime.datetime(2014, 1, 1),\ndatetime.datetime(2014, 2, 23),\ndatetime.datetime(2014, 3, 8),\ndatetime.datetime(2014, 5, 1),\ndatetime.datetime(2014, 5, 9),\ndatetime.datetime(2014, 6, 12),\ndatetime.datetime(2014, 11, 4),\n    \ndatetime.datetime(2015, 1, 1),\ndatetime.datetime(2015, 2, 23),\ndatetime.datetime(2015, 3, 8),\ndatetime.datetime(2015, 5, 1),\ndatetime.datetime(2015, 5, 9),\ndatetime.datetime(2015, 6, 12),\ndatetime.datetime(2015, 11, 4)\n]\n\nrussian_holidays_end = [\ndatetime.datetime(2013, 1, 8),\ndatetime.datetime(2013, 2, 23),\ndatetime.datetime(2013, 3, 8),\ndatetime.datetime(2013, 5, 1),\ndatetime.datetime(2013, 5, 9),\ndatetime.datetime(2013, 6, 12),\ndatetime.datetime(2013, 11, 4),\n\ndatetime.datetime(2014, 1, 8),\ndatetime.datetime(2014, 2, 23),\ndatetime.datetime(2014, 3, 8),\ndatetime.datetime(2014, 5, 1),\ndatetime.datetime(2014, 5, 9),\ndatetime.datetime(2014, 6, 12),\ndatetime.datetime(2014, 11, 4),\n\ndatetime.datetime(2015, 1, 8),\ndatetime.datetime(2015, 2, 23),\ndatetime.datetime(2015, 3, 8),\ndatetime.datetime(2015, 5, 1),\ndatetime.datetime(2015, 5, 9),\ndatetime.datetime(2015, 6, 12),\ndatetime.datetime(2015, 11, 4)\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for iterable in sorted(list(df[\"shop_name\"].unique())[:5]):\n\n    # create the size of the figure\n    #plt.figure(figsize = (30, 10))\n\n    \n    shapes = []\n    for start_date, end_date in zip(russian_holidays_start, russian_holidays_end):\n        \n    # add shaded areas for holidays 2013\n        #ax.axvspan(start_date, end_date, alpha = alpha, color = 'red')   \n        shapes.append({\n      \"x0\": start_date, \n      \"x1\": end_date, \n      \"y0\": 0, \n      \"y1\": 1, \n      \"type\": \"rect\", \n      \"xref\": \"x\", \n      \"yref\": \"paper\", \n      \"opacity\": 0.8, \n      \"fillcolor\": \"#d3d3d3\",\n        \"line_width\":0.1,\n        })\n    \n    \n    # create the subplot for Monthly sales of the each shop\n    #plt.subplot(1, 2, 1)\n    \n    #fig = make_subplots(rows=1, cols=2, layout=layout)\n    \n    # calculate the Monthly sales of each shop\n    short_df = df[df[\"shop_name\"] == iterable][[\"date\",\"item_cnt_day\"]]\n    short_df[\"date\"] = pd.to_datetime(short_df[\"date\"], format = \"%d.%m.%Y\")\n    short_df[\"YEAR\"] = short_df[\"date\"].dt.year\n    short_df = short_df.set_index(\"date\").groupby(\"YEAR\").resample(\"M\")[\"item_cnt_day\"].sum()\n    short_df = short_df.reset_index()\n    \n    # adding moving average\n    short_df[\"MA3M\"] = short_df[\"item_cnt_day\"].rolling(window = 3).mean()\n    short_df[\"MA4M\"] = short_df[\"item_cnt_day\"].rolling(window = 4).mean()\n    short_df[\"MA5M\"] = short_df[\"item_cnt_day\"].rolling(window = 5).mean()\n    \n    # assing the data to plot\n    sales = short_df[\"item_cnt_day\"]\n    dates = short_df[\"date\"]\n    \n    average_3_months = short_df[\"MA3M\"]\n    average_4_months = short_df[\"MA4M\"]\n    average_5_months = short_df[\"MA5M\"]\n    \n    # plot the data and add label\n    trace1 = go.Scatter(x=dates, y=sales,mode='lines', name = \"Monthly sales\")\n    trace2 = go.Scatter(x=dates, y=average_3_months, mode='lines', name = \"Average sales of the last 3 months\")\n    data = [trace1, trace2]\n    \n    layout = {\"shapes\":shapes}\n\n    fig = go.Figure(data=data, layout=layout)\n    \n       \n    # add title and show legend \n    #height=30, width=10\n    #layout=layout,\n    fig.update_layout(title='Monthly sales of shop {}'.format(iterable), height=600, width=1000)\n    #labels={\n                        # \"dates\":\"Time grouped by month\",\n                       #  \"sales\":'Total Monthly sales of shop {}'.format(iterable)\n                    # }\n                         \n    #######################################################################################\n    # Weekly sales\n    #######################################################################################\n    \n    \n    # calculate the Weekly sales of each shop\n    short_df = df[df[\"shop_name\"] == iterable][[\"date\",\"item_cnt_day\"]]\n    short_df[\"date\"] = pd.to_datetime(short_df[\"date\"], format = \"%d.%m.%Y\")\n    short_df[\"YEAR\"] = short_df[\"date\"].dt.year\n    short_df = short_df.set_index(\"date\").groupby(\"YEAR\").resample(\"W\")[\"item_cnt_day\"].sum()\n    short_df = short_df.reset_index()\n    \n    # adding moving average\n    short_df[\"MA3W\"] = short_df[\"item_cnt_day\"].rolling(window=3).mean()\n    short_df[\"MA4W\"] = short_df[\"item_cnt_day\"].rolling(window=4).mean()\n    short_df[\"MA5W\"] = short_df[\"item_cnt_day\"].rolling(window=5).mean()\n    \n    # assing the data to plot\n    \n    # general sales\n    sales = short_df[\"item_cnt_day\"]\n    dates = short_df[\"date\"]\n    \n    average_3_weeks = short_df[\"MA3W\"]\n    average_4_weeks = short_df[\"MA4W\"]\n    average_5_weeks = short_df[\"MA5W\"]\n        \n    # add title and show legend\n    plt.title('Weekly sales of shop {}'.format(iterable))\n    plt.ylabel('Total Weekly sales of shop {}'.format(iterable))\n    plt.xlabel(\"Time grouped by week\")\n    \n    trace3 = go.Scatter(x=dates, y=sales,mode='lines', name = \"Weekly sales\")\n    trace4 = go.Scatter(x=dates, y=average_3_months, mode='lines', name = \"Average sales of the last 3 weeks\")\n    data = [trace1, trace2]\n    \n    layout = {\"shapes\":shapes}\n\n    fig = go.Figure(data=data, layout=layout)\n    fig.update_layout(title=' sales of shop {}'.format(iterable), height=600, width=1000)\n    # general sales\n    \n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Represent the monthly sales (left plot) and weekly sales (right plot) for each item category"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Total sales and the variation on secondary axis"},{"metadata":{"trusted":true},"cell_type":"code","source":"#variation of intradays sales","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Calendar Heatmap**\n\nsee the overall activity for a certain period of time per day and per month"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_calendar = df[[\"date\", \"item_cnt_day\"]] # select columns\ndf_calendar.set_index(\"date\", inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.imshow(df_calendar)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Time Series Autocorrelation and Partial Autocorrelation plots: daily sales**\n\nThese plots are fundamental in time "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"![](http://)![](http://)![](http://)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}